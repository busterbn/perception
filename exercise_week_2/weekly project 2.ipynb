{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c414e6",
   "metadata": {},
   "source": [
    "# Robot Tracking\n",
    "\n",
    "## It is recommended that you finish the exercises from Monday, before starting the project.\n",
    "\n",
    "For this project you are given a video of some mobile robots (Robots.mp4). The task is now to track only the robots that are moving. Try to use both sparse and dense optical flow and compare the results.\n",
    "\n",
    "For sparse optical flow, draw the tracked keypoints onto each frame and try to show the frames fast enough, such that it looks like a video.\n",
    "\n",
    "For dense optical flow, represent the movement in any way you see fitting. For example by making a new image with the colors of each pixel representing the movement.\n",
    "\n",
    "\n",
    "## Handling a video with OpenCV\n",
    "\n",
    "With OpenCV we can load a video using the cv2.VideoCapture function:\n",
    "\n",
    "```python\n",
    "cap = cv2.VideoCapture('Robots.mp4')                       \n",
    "````\n",
    "\n",
    "When we need a single frame of the video, we can then use the read function of the created cv2.VideoCapture object:\n",
    "\n",
    "```python\n",
    "ret, frame = cap.read()\n",
    "```\n",
    "\n",
    "The variable ret will be either True or False indicating if the frame was read correctly. The variable frame will then be the first frame of the video. If we call the same function again, it will return the second frame of the video, and so on.\n",
    "\n",
    "Thus, if we keep calling the read function in a loop, we will be able to access every frame in the video.\n",
    "\n",
    "At the end of your program you should add a line that releases the video capture:\n",
    "\n",
    "```python\n",
    "cap.release()\n",
    "```\n",
    "  \n",
    "\n",
    "So far, when we have displayed images in JupyterLab, we have used Matplotlib (plt.imshow), instead of the standard OpenCV way cv2.imshow (OpenCV: High-level GUI). The reason for this is that Matplotlib will show the image right below your code, while OpenCV will open a new window with the image. In this project however, it might be beneficial to use cv2.imshow as we would like to display many frames after each other. So, when displaying images, try doing it the following way:\n",
    "\n",
    "```python\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(20)\n",
    "```\n",
    "\n",
    "Notice we have to give the window a name when using cv2.imshow. The second line pauses the script for 20 milliseconds before moving on.\n",
    "\n",
    "When using cv2.imshow in JupyterLab it is important to remove the image window in the end, otherwise Jupyter might crash. This is done by adding the following line to the very end of your code:\n",
    "\n",
    "```python\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    " \n",
    "Challenge (optional)\n",
    "\n",
    "If you have finished the other tasks and still have some time left, try the following:\n",
    "\n",
    " - Pick one of the moving robots and track only that one.\n",
    "\n",
    " - Try the same for the other video (Challenge.mp4).\n",
    "\n",
    "You can for example try to detect which robot is which by using a feature descriptor and matching method (SIFT, ORB, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624609b",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67f7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862209e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Robots.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow('Original Video', frame)\n",
    "    cv2.waitKey(20)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5028875",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Robots.mp4')\n",
    "\n",
    "ret, frame = cap.read()\n",
    "gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "feat1 = cv2.goodFeaturesToTrack(gray1, maxCorners=100, qualityLevel=0.3, minDistance=7)\n",
    "\n",
    "# Store the original feature points\n",
    "original_points = feat1.copy()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray2 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    feat2, status, error = cv2.calcOpticalFlowPyrLK(gray1, gray2, feat1, None)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = feat2[status == 1]\n",
    "    good_original = original_points[status == 1]\n",
    "\n",
    "    # Create a copy of the frame for drawing\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # Draw the tracks from original positions to current positions\n",
    "    for i, (new, original) in enumerate(zip(good_new, good_original)):\n",
    "        a, b = new.ravel().astype(int)\n",
    "        c, d = original.ravel().astype(int)\n",
    "        cv2.line(frame_copy, (a, b), (c, d), (0, 255, 0), 2)\n",
    "        cv2.circle(frame_copy, (a, b), 5, (0, 255, 0), -1)\n",
    "\n",
    "    cv2.imshow('Sparse Optical Flow', frame_copy)\n",
    "    cv2.waitKey(20)\n",
    "\n",
    "    # Update the previous frame and points for next iteration\n",
    "    gray1 = gray2.copy()\n",
    "    feat1 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "    # Keep original points aligned with current tracking\n",
    "    original_points = good_original.reshape(-1, 1, 2)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
